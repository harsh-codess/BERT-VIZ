# BertViz Tutorial ‚Äì Visualizing Attention in BERT

This notebook demonstrates how to use **BertViz** to explore attention mechanisms in BERT models. It includes interactive visualizations to understand how tokens attend to each other across layers and heads.

## Features

- Head View: Examine attention patterns in specific heads within a single layer.
- Model View: Observe attention distribution across all heads and layers.
- Interactive token-level attention filtering.

## How to Run

Open directly in Colab for interactive visualizations:

**[Run in Google Colab](https://colab.research.google.com/github/harsh-codess/BERT-VIZ/blob/main/bertvizualization.ipynb)**  
**üîÅ Best viewed in Colab for full interactive experience.**

## File

- `bertvisualization.ipynb`

